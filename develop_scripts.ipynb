{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten photo library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MTS, MOV, mpg, mp4 are video files\n",
    "# .psd and psb are photoshop files\n",
    "# bmp, BMP, NEF, JPG, jpg, tif, PNG, pdf are photo files\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from exif import Image as im\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# ---- get the name of the library that I am checking\n",
    "# library = sys.argv[1]\n",
    "path_list = [str(i) for i in Path(os.path.abspath('library')).glob('**/*')]\n",
    "file_list = [i for i in path_list if os.path.isfile(i)]\n",
    "ext_list = [i[i.rfind('.'):] for i in file_list]\n",
    "\n",
    "# ---- create the dataframe\n",
    "df = pd.DataFrame({'filepath': file_list, 'file_ext': ext_list})\n",
    "\n",
    "# ---- define the file type\n",
    "image_file_types = ['.bmp', '.jpg', '.jpeg', '.nef', '.tif', '.png', '.pdf']\n",
    "video_file_types = ['.mts', '.mov', '.mpg', '.mp4']\n",
    "photoshop_file_types = ['.psd', '.psb']\n",
    "\n",
    "df['file_type'] = np.where(df.file_ext.str.lower().isin(image_file_types), 'image', \n",
    "                          np.where(df.file_ext.str.lower().isin(video_file_types), 'video', \n",
    "                                  np.where(df.file_ext.str.lower().isin(photoshop_file_types), 'photoshop', 'other')))\n",
    "\n",
    "# ---- identify the metadata\n",
    "df['datetime'] = np.nan\n",
    "open_idx = df[df.file_type == 'image'].index\n",
    "\n",
    "# for i in open_idx:\n",
    "#     try:\n",
    "#         with open(df.loc[i,'filepath'], 'rb') as image_file:\n",
    "#             exif_im = im(image_file)\n",
    "#             if exif_im.has_exif:\n",
    "#                 try:\n",
    "#                     df.loc[i,'datetime'] = datetime.datetime.strptime(exif_im['datetime_original'], '%Y:%m:%d %H:%M:%S')\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             else:\n",
    "#                 pass\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/Users/alex/OneDrive - Duke University/8_coding_projects/photo_organization/library/.DS_Store',\n",
       "       '/Users/alex/OneDrive - Duke University/8_coding_projects/photo_organization/library/ob_photos_backup2/Nikon Transfer 2/118/_DSC3521.JPG'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filepath.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created sub-folder: 2015\n",
      "created sub-folder: 2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "# ---- get database\n",
    "library = sys.argv[1]\n",
    "df = pd.read_hdf('photo_database.h5', library)\n",
    "if 'datetime' not in df.columns:\n",
    "    raise Exception('database does not contain image metadata')\n",
    "    \n",
    "# ---- check that the dates are valid\n",
    "invalid_dt = df[(df.datetime > datetime.datetime.today()) | df.datetime < datetime.datetime.utcfromtimestamp(0)].index\n",
    "df.loc[invalid_dt, 'datetime'] = np.nan\n",
    "\n",
    "# ---- identify the root directory\n",
    "root = os.path.abspath('ob_photo_archive')\n",
    "if not os.path.isdir(root):\n",
    "    raise Exception('root directory not located')\n",
    "\n",
    "# ---- create folders for files that do not have metadata\n",
    "for file_type in df.file_type.unique():\n",
    "    try:\n",
    "        os.mkdir(os.path.join(root, file_type))\n",
    "        print('created sub-folder for {}'.format(file_type))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "        \n",
    "# ---- create folder for images that do no have metadata\n",
    "try:\n",
    "    os.mkdir(os.path.join(root, 'image', 'unknown'))\n",
    "    print('created sub-folder for images without metadata')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# ---- create folders for each unique year\n",
    "for year in df.datetime.dt.year.unique():\n",
    "    if pd.notnull(year):\n",
    "        try:\n",
    "            os.mkdir(os.path.join(root, 'image', str(int(year))))\n",
    "            print('created sub-folder: {}'.format(str(int(year))))\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "            \n",
    "# ---- create destination codes\n",
    "def create_destinations(df):\n",
    "    seed_since_epoch = int((datetime.datetime.now() - datetime.datetime.utcfromtimestamp(0)).total_seconds())\n",
    "    rng = np.random.RandomState(seed_since_epoch)\n",
    "\n",
    "    df['img_id'] = ['img_id_'+str(i).zfill(10) for i in rng.randint(0,1e10, len(df))]\n",
    "    df['file_name'] = [df.filepath.loc[i][df.filepath.loc[i].rfind('/')+1:] for i in df.filepath.index]\n",
    "    df['file_name'] = np.where(pd.notnull(df.datetime), 'date_'+df.datetime.dt.strftime('%Y%m%d') + '_' + df.img_id + df.file_ext.str.lower(), df.file_name)\n",
    "    destination = []\n",
    "    for i in df.index:\n",
    "        if pd.isnull(df.loc[i, 'datetime']):\n",
    "            destination.append(os.path.join(root, df.loc[i, 'file_type'], df.loc[i, 'file_name']))\n",
    "        else:\n",
    "            destination.append(os.path.join(root, df.loc[i, 'file_type'], df.loc[i, 'datetime'].strftime('%Y'), df.loc[i, 'file_name']))\n",
    "    df['destination'] = destination\n",
    "    return df\n",
    "\n",
    "def move_files(df):\n",
    "    for idx in df.index:\n",
    "        # ---- make sure that the source file exists\n",
    "        if os.path.exists(df.loc[idx, 'filepath']):\n",
    "            # ---- check to make sure that I am not overwriting anything\n",
    "            if not os.path.exists(df.loc[idx, 'destination']):\n",
    "                shutil.move(df.loc[idx,'filepath'], df.loc[idx, 'destination'])\n",
    "            # ---- if I am, rename the file and then move it\n",
    "            else:\n",
    "                if pd.isnull(df.loc[idx, 'datetime']):\n",
    "                    df.loc[idx, 'destination'] = os.path.join(root, df.loc[idx, 'file_type'], 'DUPLICATE' + df.loc[idx, 'file_name'])\n",
    "                else:\n",
    "                    df.loc[idx, 'destination'] = os.path.join(root, df.loc[idx, 'file_type'], df.loc[idx, 'datetime'].strftime('%Y'), 'DUPLICATE' + df.loc[idx, 'file_name'])\n",
    "\n",
    "                shutil.move(df.loc[idx,'filepath'], df.loc[idx, 'destination'])\n",
    "    return\n",
    "\n",
    "df = create_destinations(df)\n",
    "move_files(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from exif import Image as im\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# ---- get the name of the library that I am checking\n",
    "library = sys.argv[1]\n",
    "path_list = [str(i) for i in Path(os.path.abspath(library)).glob('**/*')]\n",
    "\n",
    "# ---- create empty lists to population\n",
    "dt = []\n",
    "img = []\n",
    "filepaths = []\n",
    "\n",
    "for item in path_list:\n",
    "    # ---- if it is a file, path list contains directories\n",
    "    if os.path.isfile(item):\n",
    "        filepaths.append(item)\n",
    "    \n",
    "        # ---- if it is an image, try and get the metadata\n",
    "        if str.endswith(str.upper(item), 'JPG') or \\\n",
    "            str.endswith(str.upper(item), 'JPEG') or \\\n",
    "            str.endswith(str.upper(item), 'PNG'):\n",
    "            img.append(True)\n",
    "            try:\n",
    "                with open(item, 'rb') as image_file:\n",
    "                    exif_im = im(image_file)\n",
    "                    if exif_im.has_exif:\n",
    "                        try:\n",
    "                            dt.append(datetime.datetime.strptime(exif_im['datetime_original'], '%Y:%m:%d %H:%M:%S'))\n",
    "                        except:\n",
    "                            dt.append(np.nan)\n",
    "                    else:\n",
    "                        dt.append(np.nan)\n",
    "            except:\n",
    "                img.append(False)\n",
    "                dt.append(np.nan)\n",
    "        else:\n",
    "            img.append(False)\n",
    "            dt.append(np.nan)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# ---- get file extensions once I have removed file directories\n",
    "ext = [i[i.rfind('.'):] for i in filepaths]\n",
    "\n",
    "df = pd.DataFrame({'filepath': filepaths,\n",
    "                   'file_type': ext,\n",
    "                   'img': img,\n",
    "                   'dt': dt})\n",
    "\n",
    "df.to_hdf('photo_database.h5', library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "df = pd.read_hdf('photo_database.h5', 'ob_photos_backup2')\n",
    "df['import'] = True\n",
    "df = df.append(pd.read_hdf('photo_database.h5', 'ob_photos_backup1'), ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image        90837\n",
       "other         1109\n",
       "video          203\n",
       "photoshop       37\n",
       "Name: file_type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.file_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964111540451578"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notnull(lib[lib.file_type == 'image'].datetime).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_dt = df[(df.datetime > datetime.datetime.today()) | (df.datetime < datetime.datetime.utcfromtimestamp(0))].index\n",
    "df.loc[invalid_dt, 'datetime'] = np.nan\n",
    "\n",
    "seed_since_epoch = int((datetime.datetime.now() - datetime.datetime.utcfromtimestamp(0)).total_seconds())\n",
    "rng = np.random.RandomState(seed_since_epoch)\n",
    "\n",
    "df['img_id'] = ['img_id_'+str(i).zfill(10) for i in rng.randint(0,1e10, len(df))]\n",
    "\n",
    "df['file_name'] = [df.filepath.loc[i][df.filepath.loc[i].rfind('/')+1:] for i in df.filepath.index]\n",
    "df['file_name'] = np.where(pd.notnull(df.datetime), 'date_'+df.datetime.dt.strftime('%Y%m%d') + '_' + df.img_id + df.file_ext.str.lower(), df.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = os.path.abspath('ob_photo_archive')\n",
    "destination = []\n",
    "for i in df.index:\n",
    "    if pd.isnull(df.loc[i, 'datetime']):\n",
    "        if df.loc[i, 'file_type'] == 'image':\n",
    "            destination.append(os.path.join(root, df.loc[i, 'file_type'], 'unknown', df.loc[i, 'file_name']))\n",
    "        else:\n",
    "            destination.append(os.path.join(root, df.loc[i, 'file_type'], df.loc[i, 'file_name']))\n",
    "    else:\n",
    "        destination.append(os.path.join(root, df.loc[i, 'file_type'], df.loc[i, 'datetime'].strftime('%Y'), df.loc[i, 'file_name']))\n",
    "df['destination'] = destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other        1071\n",
       "video          48\n",
       "image          42\n",
       "photoshop       1\n",
       "Name: file_type, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.duplicated(subset= 'destination')) & (df['import'] == True)].file_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:update2020]",
   "language": "python",
   "name": "conda-env-update2020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
